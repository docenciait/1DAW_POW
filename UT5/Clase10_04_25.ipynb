{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bQr6X-dnPrNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IkICcM6YPrKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuación webcrawling/scrapping para Seo"
      ],
      "metadata": {
        "id": "7gq9-44mFBKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 1: Extraer el título y la meta descripción\n",
        "- Aplicación SEO: Verificamos que cada página tenga un título adecuado y una descripción optimizada.\n",
        "\n"
      ],
      "metadata": {
        "id": "X1bQnlQvPin6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i20TRbgSE4dq",
        "outputId": "bf9beaf0-7cde-467a-ff8b-7e9539302267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Título: Welcome to Python.org\n",
            "Descripción: The official home of the Python Programming Language\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.python.org\"\n",
        "url2 = \"https://webscraper.io/test-sites/e-commerce/static\"\n",
        "\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Título de la página\n",
        "titulo = soup.title.string\n",
        "\n",
        "# Meta descripción\n",
        "meta_descripcion = soup.find('meta', attrs={'name': 'description'})\n",
        "# descripcion = meta_descripcion['content'] if meta_descripcion else \"No tiene descripción\"\n",
        "\n",
        "if meta_descripcion:\n",
        "    descripcion = meta_descripcion['content']\n",
        "else:\n",
        "    descripcion = \"No tiene descripción\"\n",
        "\n",
        "print(\"Título:\", titulo)\n",
        "print(\"Descripción:\", descripcion)\n",
        "#print(soup.prettify())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 2: Revisar estructura de encabezados H1, H2, H3\n",
        "\n",
        "Aplicación SEO: Un solo <h1>, uso jerárquico de encabezados. Puedes revisar si una página está correctamente estructurada."
      ],
      "metadata": {
        "id": "IjRAPlddPyu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encabezados = {}\n",
        "for tag in ['h1', 'h2', 'h3']:\n",
        "    encabezados[tag] = [h.get_text(strip=True) for h in soup.find_all(tag)]\n",
        "\n",
        "print(encabezados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTzOLEZqGe5A",
        "outputId": "8f7df3b6-e247-4362-8bba-1df2325cd49a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'h1': ['', 'Functions Defined', 'Compound Data Types', 'Intuitive Interpretation', 'All the Flow You’d Expect', 'Quick & Easy to Learn'], 'h2': ['Get Started', 'Download', 'Docs', 'Jobs', 'Latest News', 'Upcoming Events', 'Success Stories', 'Use Python for…', '>>>Python Software Foundation'], 'h3': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 3: Verificar si hay enlaces rotos (broken links)\n",
        "Aplicación SEO: Detectar enlaces rotos que afectan el posicionamiento y la experiencia del usuario."
      ],
      "metadata": {
        "id": "eAUAQcxYP7Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "enlaces = soup.find_all('a', href=True)\n",
        "for enlace in enlaces[:10]:  # Limita para pruebas\n",
        "    link = urljoin(url2, enlace['href'])\n",
        "    try:\n",
        "        r = requests.head(link, timeout=5)\n",
        "        if r.status_code >= 400:\n",
        "            print(\"Enlace roto:\", link, \"Status:\", r.status_code)\n",
        "        else:\n",
        "            print(\"Enlace OK:\", r.status_code)\n",
        "    except requests.RequestException:\n",
        "        print(\"Enlace roto:\", link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-yDmO4GpGT",
        "outputId": "4baf20b7-95dc-4c2c-8fea-3c5586aca1e4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enlace OK: 200\n",
            "Enlace OK: 200\n",
            "Enlace OK: 200\n",
            "Enlace OK: 301\n",
            "Enlace OK: 302\n",
            "Enlace OK: 200\n",
            "Enlace OK: 200\n",
            "Enlace roto: https://webscraper.io/community/ Status: 404\n",
            "Enlace OK: 200\n",
            "Enlace OK: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 4: Verificar imágenes sin atributo alt\n",
        "Aplicación SEO: Las imágenes sin atributo alt perjudican la accesibilidad y el SEO de imágenes.\n",
        "\n"
      ],
      "metadata": {
        "id": "a2uUrll9QC0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagenes = soup.find_all('img')\n",
        "sin_alt = [img['src'] for img in imagenes if not img.get('alt')]\n",
        "\n",
        "print(\"Imágenes sin 'alt':\", sin_alt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqh4pkc_Hl0e",
        "outputId": "6dc9cc08-f475-48b6-c526-85a7394177b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes sin 'alt': []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 5: Verificar la presencia del atributo canonical\n",
        "El atributo rel=\"canonical\" evita contenido duplicado indicando la versión principal de una página.\n",
        "\n",
        "Aplicación SEO: Asegura que se indica cuál es la URL original de la página.\n",
        "\n"
      ],
      "metadata": {
        "id": "SX13ap0YQT7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "canonical = soup.find('link', rel='canonical')\n",
        "if canonical:\n",
        "    print(\"Canonical:\", canonical['href'])\n",
        "else:\n",
        "    print(\"No se encontró etiqueta canonical.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QdoGeC3QeE8",
        "outputId": "4c358e95-11b6-4019-81b0-4a7b9662b6c8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canonical: https://webscraper.io/test-sites/e-commerce/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 6: Listar todas las URLs internas y externas\n",
        "Aplicación SEO: Ayuda a entender la estructura de enlaces internos y salientes.\n",
        "\n"
      ],
      "metadata": {
        "id": "61DuklJkQpJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse\n",
        "\n",
        "internas = []\n",
        "externas = []\n",
        "\n",
        "for a in soup.find_all('a', href=True):\n",
        "    href = a['href']\n",
        "    if href.startswith('#') or href.startswith('mailto:') or href.startswith('tel:'):\n",
        "        continue\n",
        "    if urlparse(href).netloc == \"\" or urlparse(href).netloc == urlparse(url).netloc:\n",
        "        internas.append(href)\n",
        "    else:\n",
        "        externas.append(href)\n",
        "\n",
        "print(\"Enlaces internos:\", internas[:5])\n",
        "print(\"Enlaces externos:\", externas[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TiYH3h7QoS_",
        "outputId": "a77d181b-1c79-427a-e4b8-101135b3a57a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enlaces internos: ['/', '/', '/cloud-scraper', '/pricing', '/documentation']\n",
            "Enlaces externos: ['https://forum.webscraper.io/', 'https://chromewebstore.google.com/detail/web-scraper-free-web-scra/jnhgnonknehpejjnehehllkliplmbmhn?hl=en', 'https://cloud.webscraper.io/', 'https://webscraper.io/downloads/Web_Scraper_Media_Kit.zip', 'https://forum.webscraper.io/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 7: Revisar si el archivo robots.txt permite el acceso\n",
        "Aplicación SEO: Verifica si la página permite ser rastreada por motores de búsqueda.\n",
        "\n"
      ],
      "metadata": {
        "id": "nsIpx42FQybe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robots_url = url + \"/robots.txt\"\n",
        "try:\n",
        "    r = requests.get(robots_url)\n",
        "    print(\"Contenido de robots.txt:\\n\", r.text[:300])\n",
        "except:\n",
        "    print(\"No se pudo obtener robots.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuwYqLveQxyE",
        "outputId": "a6ffc211-d8d8-4522-97ce-4f5edb947228"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenido de robots.txt:\n",
            " # Directions for robots.  See this URL:\n",
            "# http://www.robotstxt.org/robotstxt.html\n",
            "# for a description of the file format.\n",
            "\n",
            "User-agent: HTTrack\n",
            "User-agent: puf\n",
            "User-agent: MSIECrawler\n",
            "Disallow: /\n",
            "\n",
            "# The Krugle web crawler (though based on Nutch) is OK.\n",
            "User-agent: Krugle\n",
            "Allow: /\n",
            "Disallow: /~guido/or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 8: Detectar páginas sin etiquetas <meta name=\"robots\">\n",
        "Aplicación SEO: Se puede indicar noindex, nofollow, etc. Esta etiqueta debe estar bien configurada.\n",
        "\n"
      ],
      "metadata": {
        "id": "dzI5RKiPQxhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robots_meta = soup.find('meta', attrs={'name': 'robots'})\n",
        "if robots_meta:\n",
        "    print(\"Meta robots:\", robots_meta['content'])\n",
        "else:\n",
        "    print(\"No se encontró etiqueta meta robots.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iga4fDXNSQnY",
        "outputId": "b6d9aa06-2cd3-43c8-f71c-744410ad47f8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontró etiqueta meta robots.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "leLdSjHtSfWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 9: Verificar si está el sitemap.xml"
      ],
      "metadata": {
        "id": "ifD6sl7xTdo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "# 2. Posibles rutas de sitemap\n",
        "posibles_sitemaps = [url, url2]\n",
        "\n",
        "# 3. Verificación de existencia\n",
        "for path in posibles_sitemaps:\n",
        "\n",
        "    try:\n",
        "        response = requests.head(path, timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"✅ Sitemap encontrado en: {path}\")\n",
        "        else:\n",
        "            print(f\"❌ No encontrado: {path} (Status {response.status_code})\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al acceder a {path}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLiMBAEBSvJO",
        "outputId": "2d4b5fa1-b671-426b-81ab-3e79f7673cd1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sitemap encontrado en: https://www.python.org\n",
            "✅ Sitemap encontrado en: https://webscraper.io/test-sites/e-commerce/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 10: Detectar múltiples etiquetas <title> (error común)\n",
        "Aplicación SEO: Tener más de un <title> puede confundir a los motores de búsqueda.\n",
        "\n"
      ],
      "metadata": {
        "id": "g8fSEzHVTuz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titulos = soup.find_all('title')\n",
        "if len(titulos) > 1:\n",
        "    print(f\"¡Cuidado! Hay {len(titulos)} etiquetas <title>\")\n",
        "else:\n",
        "    print(\"Etiqueta <title> correcta:\", titulos[0].string if titulos else \"No hay título\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asQVY4HxT2xv",
        "outputId": "2805b509-6ce0-467a-a0a4-6ae1421f146a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiqueta <title> correcta: Static | Web Scraper Test Sites\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 11: Detectar páginas sin favicon\n",
        "Aplicación SEO: Aunque no afecta directamente al ranking, es importante para la apariencia en resultados y marcadores."
      ],
      "metadata": {
        "id": "1t_i9fFPT921"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "favicon = None\n",
        "for link in soup.find_all(\"link\"):\n",
        "    rel = link.get(\"rel\")\n",
        "    if rel and any(\"icon\" in r.lower() for r in rel):\n",
        "        favicon = link\n",
        "        break\n",
        "\n",
        "if favicon and favicon.get(\"href\"):\n",
        "    print(\"Favicon encontrado:\", favicon[\"href\"])\n",
        "else:\n",
        "    print(\"No tiene favicon\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqTCe7I0UBA-",
        "outputId": "3655cc37-2cba-47c6-8947-4183803dc045"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Favicon encontrado: /favicon.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 12: Verificar el uso de etiquetas <strong> y <em>\n",
        "Aplicación SEO: Útil para destacar contenido relevante y palabras clave.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0BvAWSdUWwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strongs = soup.find_all('strong')\n",
        "ems = soup.find_all('em')\n",
        "\n",
        "print(f\"<strong>: {len(strongs)} - <em>: {len(ems)}\")\n",
        "\n",
        "if len(strongs) + len(ems) == 0:\n",
        "    print(\"No se están destacando palabras clave con <strong> o <em>\")"
      ],
      "metadata": {
        "id": "gFpPzwqDUnFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 13: EVerificar uso de Open Graph (Facebook) y Twitter Cards\n"
      ],
      "metadata": {
        "id": "cOhEZAFMUbug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "og_tags = soup.find_all('meta', property=lambda p: p and p.startswith('og:'))\n",
        "twitter_tags = soup.find_all('meta', attrs={'name': lambda n: n and n.startswith('twitter:')})\n",
        "\n",
        "print(\"Etiquetas Open Graph:\", [tag['property'] for tag in og_tags])\n",
        "print(\"Etiquetas Twitter:\", [tag['name'] for tag in twitter_tags])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9-CkoWtUrS4",
        "outputId": "0921c94d-cc4b-4d6e-d227-4a0822797849"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas Open Graph: ['og:type', 'og:site_name', 'og:title', 'og:description', 'og:image', 'og:image:secure_url', 'og:url']\n",
            "Etiquetas Twitter: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 14: Extraer y analizar la densidad de palabras clave"
      ],
      "metadata": {
        "id": "0irAg6PwWCCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "texto = soup.get_text().lower()\n",
        "palabras = re.findall(r'\\b\\w{4,}\\b', texto)  # solo palabras de 4 letras o más\n",
        "stopwords = {'de', 'la', 'y', 'el', 'en', 'los', 'las', 'con', 'por', 'una', 'para', 'que', 'del', 'sus', 'más'}\n",
        "\n",
        "# Filtra y cuenta\n",
        "palabras_filtradas = [p for p in palabras if p not in stopwords]\n",
        "top_keywords = Counter(palabras_filtradas).most_common(10)\n",
        "\n",
        "print(\"Top 10 palabras clave:\", top_keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5YHuq41WD-M",
        "outputId": "d5f793a4-cb2b-47fb-a690-0ecf927a2829"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 palabras clave: [('python', 56), ('2025', 15), ('news', 12), ('events', 11), ('more', 11), ('community', 9), ('with', 8), ('docs', 7), ('code', 6), ('other', 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EJERCICIO PRÁCTICO"
      ],
      "metadata": {
        "id": "5P5zCwGSWvZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "def analyze_url(url):\n",
        "    result = {\n",
        "        \"URL\": url,\n",
        "        \"Title\": None,\n",
        "        \"Title Length\": None,\n",
        "        \"Meta Description\": None,\n",
        "        \"Meta Description Length\": None,\n",
        "        \"H1 Count\": None,\n",
        "        \"Images Missing Alt\": None,\n",
        "        \"Canonical Tag\": None,\n",
        "        \"Internal Links Count\": None,\n",
        "        \"External Links Count\": None,\n",
        "        \"Broken Links Count\": None,\n",
        "        \"Broken Links Sample\": None,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code != 200:\n",
        "            result[\"Title\"] = f\"Error: status {response.status_code}\"\n",
        "            return result\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Título\n",
        "        if soup.title and soup.title.string:\n",
        "            title = soup.title.string.strip()\n",
        "            result[\"Title\"] = title\n",
        "            result[\"Title Length\"] = len(title)\n",
        "        else:\n",
        "            result[\"Title\"] = \"No Title\"\n",
        "            result[\"Title Length\"] = 0\n",
        "\n",
        "        # Meta descripción\n",
        "        meta_desc = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
        "        if meta_desc and meta_desc.get(\"content\"):\n",
        "            desc = meta_desc[\"content\"].strip()\n",
        "            result[\"Meta Description\"] = desc\n",
        "            result[\"Meta Description Length\"] = len(desc)\n",
        "        else:\n",
        "            result[\"Meta Description\"] = \"No Meta Description\"\n",
        "            result[\"Meta Description Length\"] = 0\n",
        "\n",
        "        # H1\n",
        "        h1_tags = soup.find_all(\"h1\")\n",
        "        result[\"H1 Count\"] = len(h1_tags)\n",
        "\n",
        "        # Imágenes sin alt\n",
        "        images = soup.find_all(\"img\")\n",
        "        missing_alt = sum(1 for img in images if not img.get(\"alt\"))\n",
        "        result[\"Images Missing Alt\"] = missing_alt\n",
        "\n",
        "        # Canonical\n",
        "        canonical = soup.find(\"link\", rel=lambda val: val and \"canonical\" in val.lower())\n",
        "        result[\"Canonical Tag\"] = canonical[\"href\"] if canonical and canonical.get(\"href\") else \"No canonical\"\n",
        "\n",
        "        # Enlaces\n",
        "        parsed_base = urlparse(url)\n",
        "        internal_links = []\n",
        "        external_links = []\n",
        "        broken_links = []\n",
        "\n",
        "        for a in soup.find_all(\"a\", href=True):\n",
        "            href = a[\"href\"]\n",
        "            if href.startswith(\"#\") or href.startswith(\"mailto:\") or href.startswith(\"tel:\"):\n",
        "                continue\n",
        "            full_link = urljoin(url, href)\n",
        "            parsed_link = urlparse(full_link)\n",
        "            if parsed_link.netloc == \"\" or parsed_link.netloc == parsed_base.netloc:\n",
        "                internal_links.append(full_link)\n",
        "            else:\n",
        "                external_links.append(full_link)\n",
        "\n",
        "            # Comprobación de enlace roto\n",
        "            try:\n",
        "                r = requests.head(full_link, allow_redirects=True, timeout=5)\n",
        "                if r.status_code >= 400:\n",
        "                    broken_links.append(full_link)\n",
        "            except:\n",
        "                broken_links.append(full_link)\n",
        "\n",
        "        result[\"Internal Links Count\"] = len(internal_links)\n",
        "        result[\"External Links Count\"] = len(external_links)\n",
        "        result[\"Broken Links Count\"] = len(broken_links)\n",
        "        result[\"Broken Links Sample\"] = \"\\n\".join(broken_links[:3]) if broken_links else \"Ninguno\"\n",
        "\n",
        "    except Exception as e:\n",
        "        result[\"Title\"] = f\"Error: {e}\"\n",
        "\n",
        "    return result\n",
        "\n",
        "def main():\n",
        "    urls = [\n",
        "        # \"http://books.toscrape.com/\",\n",
        "        # \"http://quotes.toscrape.com/\",\n",
        "        # \"https://demo.opencart.com/\"\n",
        "        \"https://www.python.org\",\n",
        "        \"https://webscraper.io/test-sites/e-commerce/static\"\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for url in urls:\n",
        "        print(f\"Analizando: {url}\")\n",
        "        data = analyze_url(url)\n",
        "        results.append(data)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_excel(\"seo_audit_with_broken_links.xlsx\", index=False)\n",
        "    print(\"¡Informe completo exportado a seo_audit_with_broken_links.xlsx!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVWKM9UGW4cj",
        "outputId": "3d6eaed8-b3b2-46ee-e9a3-9efa067f2671"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analizando: https://www.python.org\n",
            "Analizando: https://webscraper.io/test-sites/e-commerce/static\n",
            "¡Informe completo exportado a seo_audit_with_broken_links.xlsx!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio: Analizar palabras clave SEO y exportar a Excel\n",
        "## Objetivo\n",
        "\n",
        "- Extraer el texto visible de una página web.\n",
        "\n",
        "- Contar cuántas veces aparece cada palabra.\n",
        "\n",
        "- Eliminar las stopwords (palabras vacías comunes).\n",
        "\n",
        "```\n",
        "\n",
        "stopwords = ['de', 'la', ...']'\n",
        "```\n",
        "\n",
        "\n",
        "- Quedarse con las más relevantes (longitud > 3).\n",
        "\n",
        "- Exportar a un archivo Excel con las columnas:\n",
        "Palabra, Frecuencia."
      ],
      "metadata": {
        "id": "quCIiPZPYsx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h4qtGPyGZ37n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ **Test de Autoevaluación: SEO On-Page con Python (20 preguntas)**\n",
        "**Instrucciones:**  Elige la opción correcta en cada pregunta. Solo una respuesta es válida por ítem.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "🧠 **1. Fundamentos y herramientas**\n",
        "\n",
        "**1.1.**  ¿Qué librería en Python es más adecuada para analizar el HTML de una página?\n",
        "\n",
        "A) urllib\n",
        "\n",
        "B) re\n",
        "\n",
        "C) BeautifulSoup\n",
        "\n",
        "D) time\n",
        "\n",
        "\n",
        "**1.2.**  ¿Cuál de estas librerías se utiliza para hacer peticiones HTTP?\n",
        "\n",
        "A) matplotlib\n",
        "\n",
        "B) requests\n",
        "\n",
        "C) pandas\n",
        "\n",
        "D) os\n",
        "\n",
        "**1.3.**  ¿Qué librería se usa para exportar datos a Excel desde Python?\n",
        "\n",
        "A) numpy\n",
        "\n",
        "B) selenium\n",
        "\n",
        "C) pandas\n",
        "\n",
        "D) hashlib\n",
        "\n",
        "**1.4.**  ¿Cuál es el objetivo principal de BeautifulSoup?\n",
        "\n",
        "A) Controlar formularios\n",
        "\n",
        "B) Parsear (analizar) HTML y XML\n",
        "\n",
        "C) Dibujar gráficos\n",
        "\n",
        "D) Descargar archivos binarios\n",
        "\n",
        "**1.5.**  ¿Qué función tiene `urljoin()` en el análisis de enlaces?\n",
        "\n",
        "A) Analiza direcciones IP\n",
        "\n",
        "B) Convierte URL a mayúsculas\n",
        "\n",
        "C) Une URLs base con relativas\n",
        "\n",
        "D) Divide una URL en partes\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "🔍 **2. Elementos SEO on-page**\n",
        "\n",
        "**2.1.**  ¿Cuál es la etiqueta principal que debe representar el título del contenido?\n",
        "\n",
        "A) `<title>`\n",
        "\n",
        "B) `<h1>`\n",
        "\n",
        "C) `<meta>`\n",
        "\n",
        "D) `<header>`\n",
        "\n",
        "**2.2.**  ¿Cuál es la longitud recomendada para una etiqueta `<title>`?\n",
        "\n",
        "A) Máximo 20 caracteres\n",
        "\n",
        "B) Entre 60 y 70 caracteres\n",
        "\n",
        "C) Más de 100 caracteres\n",
        "\n",
        "D) No tiene límite\n",
        "\n",
        "**2.3.**  ¿Qué atributo de la imagen se analiza para evaluar la accesibilidad y el SEO?\n",
        "\n",
        "A) `src`\n",
        "\n",
        "B) `href`\n",
        "\n",
        "C) `alt`\n",
        "\n",
        "D) `class`\n",
        "\n",
        "**2.4.**  ¿Cuál de estos códigos HTTP indica un enlace roto?\n",
        "\n",
        "A) 200\n",
        "\n",
        "B) 301\n",
        "\n",
        "C) 403\n",
        "\n",
        "D) 404\n",
        "\n",
        "**2.5.**  ¿Qué metaetiqueta se usa para evitar que una página sea indexada?\n",
        "\n",
        "A) `<meta name=\"robots\" content=\"noindex\">`\n",
        "\n",
        "B) `<meta charset=\"UTF-8\">`\n",
        "\n",
        "C) `<meta name=\"canonical\">`\n",
        "\n",
        "D) `<meta name=\"nofollow\">`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "✍️ **3. Análisis de contenido y palabras clave**\n",
        "\n",
        "**3.1.**  ¿Qué hace la función `get_text()` en BeautifulSoup?\n",
        "\n",
        "A) Elimina los enlaces\n",
        "\n",
        "B) Extrae todo el texto visible del HTML\n",
        "\n",
        "C) Extrae solo el contenido de imágenes\n",
        "\n",
        "D) Corta el contenido\n",
        "\n",
        "**3.2.**  ¿Qué son las “stopwords”?\n",
        "\n",
        "A) Enlaces rotos\n",
        "\n",
        "B) Palabras que deben destacarse\n",
        "\n",
        "C) Palabras comunes que se excluyen del análisis\n",
        "\n",
        "D) Palabras duplicadas\n",
        "\n",
        "**3.3.**  ¿Para qué se usa `collections.Counter()`?\n",
        "\n",
        "A) Ordenar listas alfabéticamente\n",
        "\n",
        "B) Contar elementos repetidos\n",
        "\n",
        "C) Dividir cadenas de texto\n",
        "\n",
        "D) Verificar enlaces rotos\n",
        "\n",
        "**3.4.**  ¿Qué estructura de datos devuelve `Counter(palabras)`?\n",
        "\n",
        "A) Lista\n",
        "\n",
        "B) Diccionario\n",
        "\n",
        "C) Tupla\n",
        "\n",
        "D) Conjunto (set)\n",
        "\n",
        "**3.5.**  ¿Cuál es un buen indicador de que una página tiene contenido suficiente para SEO?\n",
        "\n",
        "A) Más de 50 palabras\n",
        "\n",
        "B) Más de 100 enlaces\n",
        "\n",
        "C) Más de 300 palabras de contenido real\n",
        "\n",
        "D) Tener un sitemap\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "🧪 **4. Práctica con enlaces, imágenes y exportación**\n",
        "\n",
        "**4.1.**  ¿Cómo detectamos imágenes sin atributo `alt` con BeautifulSoup?\n",
        "\n",
        "A) `img.get(\"src\") == None`\n",
        "\n",
        "B) `img.get(\"alt\") == None`\n",
        "\n",
        "C) `img.has_class(\"alt\")`\n",
        "\n",
        "D) `img.text == \"\"`\n",
        "\n",
        "\n",
        "**4.2.**  ¿Qué atributo usamos para identificar un enlace canónico?\n",
        "\n",
        "A) `rel=\"canonical\"`\n",
        "\n",
        "B) `name=\"robots\"`\n",
        "\n",
        "C) `meta=\"description\"`\n",
        "\n",
        "D) `href=\"canonical\"`\n",
        "\n",
        "\n",
        "**4.3.**  ¿Qué diferencia hay entre un enlace interno y uno externo?\n",
        "\n",
        "A) El interno usa `mailto:`\n",
        "\n",
        "B) El externo tiene un dominio distinto\n",
        "\n",
        "C) El externo no tiene protocolo\n",
        "\n",
        "D) El interno es siempre un script\n",
        "\n",
        "\n",
        "**4.4.**  ¿Qué código HTTP representa acceso prohibido?\n",
        "\n",
        "A) 302\n",
        "\n",
        "B) 200\n",
        "\n",
        "C) 403\n",
        "\n",
        "D) 100\n",
        "\n",
        "**4.5.**  ¿Qué función usamos en pandas para guardar un DataFrame en Excel?\n",
        "\n",
        "A) `save_as_excel()`\n",
        "\n",
        "B) `export_excel()`\n",
        "\n",
        "C) `to_excel()`\n",
        "\n",
        "D) `write_xls()`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "🧩 **5. Verificación de estructura SEO**\n",
        "\n",
        "**5.1.**  ¿Qué pasa si una página tiene varios `<h1>`?\n",
        "\n",
        "A) Mejora el SEO\n",
        "\n",
        "B) Se considera contenido duplicado\n",
        "\n",
        "C) Rompe el HTML\n",
        "\n",
        "D) Afecta la jerarquía semántica\n",
        "\n",
        "**5.2.**  ¿Por qué es importante verificar enlaces rotos?\n",
        "\n",
        "A) Rompen la maquetación\n",
        "\n",
        "B) Penalizan el SEO y afectan al usuario\n",
        "\n",
        "C) Solo son molestos en móviles\n",
        "\n",
        "D) Impiden cargar CSS\n",
        "\n",
        "**5.3.**  ¿Qué extensión debe tener el archivo de un sitemap estándar?\n",
        "\n",
        "A) `.html`\n",
        "\n",
        "B) `.txt`\n",
        "\n",
        "C) `.json`\n",
        "\n",
        "D) `.xml`\n",
        "\n",
        "**5.4.**  ¿Qué significa que una página tenga un “canonical tag”?\n",
        "\n",
        "A) Es la página más vista\n",
        "\n",
        "B) Es la versión original para evitar duplicación\n",
        "\n",
        "C) Es la que carga más rápido\n",
        "\n",
        "D) Es la última página actualizada\n",
        "\n",
        "**5.5.**  ¿Dónde se suele declarar el `favicon` en HTML?\n",
        "\n",
        "A) En `<footer>`\n",
        "\n",
        "B) En `<body>`\n",
        "\n",
        "C) En `<link rel=\"icon\">` dentro de `<head>`\n",
        "\n",
        "D) En `robots.txt`"
      ],
      "metadata": {
        "id": "TYts04zxZ8r3"
      }
    }
  ]
}