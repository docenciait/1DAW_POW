{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af2dcc1",
   "metadata": {},
   "source": [
    "üîπ **Ejercicio 1: Comprobar la estructura jer√°rquica de encabezados HTML** \n",
    "**Objetivo:**  Aseg√∫rate de que una p√°gina tenga solo un `<h1>`, y que los encabezados `<h2>` y `<h3>` est√©n bien organizados.\n",
    " \n",
    "- Extrae todos los encabezados `<h1>`, `<h2>`, `<h3>`.\n",
    " \n",
    "- Verifica que solo exista **\n",
    "Verifica que solo exista un `<h1>`** .\n",
    " \n",
    "- Exporta la lista de encabezados y su jerarqu√≠a a un archivo Excel o CSV.\n",
    " \n",
    "- Marca si hay errores de estructura.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 2: Analizar velocidad de respuesta (Time to First Byte)** \n",
    "**Objetivo:**  Detectar p√°ginas con tiempo de carga lento.\n",
    " \n",
    "- Usa `requests.get()` con `response.elapsed.total_seconds()` para medir el tiempo de carga.\n",
    " \n",
    "- Clasifica la velocidad:\n",
    "\n",
    " \n",
    "  - üü¢ < 0.5s\n",
    " \n",
    "  - üü° 0.5s - 1s\n",
    " \n",
    "  - üî¥ > 1s\n",
    " \n",
    "- Aplica a una lista de URLs.\n",
    " \n",
    "- Exporta los resultados a Excel con: URL, TTFB, categor√≠a.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 3: Detecci√≥n de metadatos sociales** \n",
    "**Objetivo:**  Verificar si una p√°gina tiene etiquetas Open Graph (`og:`) y Twitter Cards.\n",
    " \n",
    "- Extrae todas las etiquetas `<meta>` que comiencen por `og:` o `twitter:`.\n",
    " \n",
    "- Reporta las que faltan (por ejemplo: `og:title`, `og:description`, etc).\n",
    " \n",
    "- Exporta los resultados por URL: etiquetas presentes, etiquetas ausentes.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 4: Comprobaci√≥n de enlaces internos sin HTTPS** \n",
    "**Objetivo:**  Detectar enlaces internos que no utilizan HTTPS.\n",
    " \n",
    "- Extrae todos los `<a>` con `href`.\n",
    " \n",
    "- Revisa si apuntan a un dominio interno **\n",
    "Revisa si apuntan a un dominio interno sin `https://`** .\n",
    " \n",
    "- Exporta a CSV: texto del enlace, destino, estado de seguridad (`seguro` / `no seguro`).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 5: Extraer im√°genes externas y analizar tama√±os** \n",
    "**Objetivo:**  Detectar im√°genes externas que puedan afectar rendimiento SEO.\n",
    " \n",
    "- Encuentra todas las etiquetas `<img>` cuyo `src` apunte a otro dominio.\n",
    " \n",
    "- Intenta descargar el archivo y obtener su tama√±o (en KB).\n",
    " \n",
    "- Marca im√°genes de m√°s de 300 KB como \"pesadas\".\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 6: Verificaci√≥n de presencia de Google Analytics** \n",
    "**Objetivo:**  Comprobar si una web incluye el script de Google Analytics.\n",
    " \n",
    "- Analiza el HTML en busca de `gtag`, `ga.js`, `analytics.js`, `UA-`, `G-`.\n",
    " \n",
    "- Marca si se detecta el c√≥digo o no.\n",
    " \n",
    "- Exporta la informaci√≥n por p√°gina auditada.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ Ejercicio 7: Comprobar duplicidad de `<title>` y `<meta description>` entre p√°ginas** \n",
    "**Objetivo:**  Identificar t√≠tulos o descripciones duplicadas en m√∫ltiples URLs.\n",
    " \n",
    "- Crea una lista de p√°ginas.\n",
    " \n",
    "- Extrae `<title>` y `<meta name=\"description\">` de cada una.\n",
    " \n",
    "- Detecta repeticiones exactas.\n",
    " \n",
    "- Exporta un informe agrupado por duplicados.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 8: Densidad de palabras clave por p√°gina** \n",
    "**Objetivo:**  Medir si hay sobreoptimizaci√≥n (keyword stuffing).\n",
    " \n",
    "- Extrae texto visible de la p√°gina.\n",
    " \n",
    "- Cuenta palabras clave principales.\n",
    " \n",
    "- Calcula su densidad sobre el total del contenido.\n",
    " \n",
    "- Marca si alguna supera el 5% del total (riesgo SEO).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 9: Validar sitemap.xml** \n",
    "**Objetivo:**  Verificar si el archivo `sitemap.xml` existe y contiene URLs v√°lidas.\n",
    " \n",
    "- Intenta acceder a `/sitemap.xml`.\n",
    " \n",
    "- Si existe, parsea el XML.\n",
    " \n",
    "- Valida que haya al menos 10 URLs.\n",
    " \n",
    "- Exporta el listado a Excel o CSV.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üîπ **Ejercicio 10: Generar informe de auditor√≠a SEO b√°sica** \n",
    "**Objetivo:**  Combinar todos los an√°lisis en un solo informe.\n",
    "\n",
    "Para cada URL:\n",
    "\n",
    " \n",
    "- ¬øTiene `<title>` y `<meta description>`?\n",
    " \n",
    "- ¬øTiene `<h1>` √∫nico?\n",
    " \n",
    "- ¬øEnlaces rotos?\n",
    " \n",
    "- ¬øIm√°genes sin `alt`?\n",
    " \n",
    "- ¬øSitemap? ¬ørobots.txt?\n",
    " \n",
    "- ¬øCanonical?\n",
    " \n",
    "- ¬øTiempo de respuesta?\n",
    "\n",
    "**Exporta todo a un √∫nico Excel**  con una fila por URL y columnas por criterio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f41a3",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 1: Estructura jer√°rquica de encabezados HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8595bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encabezados encontrados: {'h1': ['Test Sites'], 'h2': ['E-commerce training site'], 'h3': ['Top items being scraped right now']}\n",
      "‚úÖ Estructura de encabezados v√°lida\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://webscraper.io/test-sites/e-commerce/static\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "encabezados = {}\n",
    "\n",
    "for tag in [\"h1\", \"h2\", \"h3\"]:\n",
    "    encabezados[tag] = []  # Inicializa la lista para cada tipo de encabezado\n",
    "    elementos = soup.find_all(tag)\n",
    "    for h in elementos:\n",
    "        texto = h.get_text(strip=True)\n",
    "        encabezados[tag].append(texto)\n",
    "\n",
    "print(\"Encabezados encontrados:\", encabezados)\n",
    "\n",
    "# Verificaci√≥n adicional\n",
    "if len(encabezados[\"h1\"]) != 1:\n",
    "    print(\"‚ö†Ô∏è Error: debe haber exactamente un <h1>\")\n",
    "else:\n",
    "    print(\"‚úÖ Estructura de encabezados v√°lida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fae73",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 2: An√°lisis de velocidad de respuesta (TTFB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b89abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de respuesta (TTFB): 0.125 segundos\n",
      "üü¢ R√°pido\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "response = requests.get(url)\n",
    "ttfb = response.elapsed.total_seconds()\n",
    "print(f\"Tiempo de respuesta (TTFB): {ttfb:.3f} segundos\")\n",
    "\n",
    "if ttfb < 0.5:\n",
    "    print(\"üü¢ R√°pido\")\n",
    "elif ttfb < 1.0:\n",
    "    print(\"üü° Medio\")\n",
    "else:\n",
    "    print(\"üî¥ Lento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a430a",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 3: Detecci√≥n de metadatos sociales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303792e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG encontrados: ['og:title', 'og:description', 'og:type', 'og:url', 'og:image']\n",
      "OG faltantes: []\n",
      "Twitter encontrados: []\n",
      "Twitter faltantes: ['twitter:card', 'twitter:title', 'twitter:description', 'twitter:image']\n"
     ]
    }
   ],
   "source": [
    "og_expect = ['og:title', 'og:description', 'og:image', 'og:url']\n",
    "twitter_expect = ['twitter:card', 'twitter:title', 'twitter:description', 'twitter:image']\n",
    "\n",
    "og_tags = [tag.get('property') for tag in soup.find_all('meta', property=True) if tag['property'].startswith('og:')]\n",
    "twitter_tags = [tag.get('name') for tag in soup.find_all('meta', attrs={'name': True}) if tag['name'].startswith('twitter:')]\n",
    "\n",
    "print(\"OG encontrados:\", og_tags)\n",
    "print(\"OG faltantes:\", [tag for tag in og_expect if tag not in og_tags])\n",
    "print(\"Twitter encontrados:\", twitter_tags)\n",
    "print(\"Twitter faltantes:\", [tag for tag in twitter_expect if tag not in twitter_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38267b3d",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 4: Enlaces internos sin HTTPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be025ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "parsed_base = urlparse(url)\n",
    "inseguros = []\n",
    "\n",
    "for a in soup.find_all(\"a\", href=True):\n",
    "    full_url = urljoin(url, a[\"href\"])\n",
    "    parsed = urlparse(full_url)\n",
    "    if parsed.netloc == parsed_base.netloc and not full_url.startswith(\"https://\"):\n",
    "        inseguros.append(full_url)\n",
    "\n",
    "print(\"Enlaces internos sin HTTPS:\", inseguros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c0836",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 5: Im√°genes externas y su tama√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4560e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_imgs = [img[\"src\"] for img in soup.find_all(\"img\", src=True) if urlparse(img[\"src\"]).netloc not in [\"\", urlparse(url).netloc]]\n",
    "pesadas = []\n",
    "\n",
    "for img_url in external_imgs:\n",
    "    try:\n",
    "        img_resp = requests.head(img_url, allow_redirects=True)\n",
    "        size = int(img_resp.headers.get(\"Content-Length\", 0)) / 1024\n",
    "        if size > 300:\n",
    "            pesadas.append((img_url, size))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Im√°genes externas > 300KB:\", pesadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19447337",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 6: Verificaci√≥n de Google Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087825be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(code in response.text for code in [\"UA-\", \"G-\", \"gtag(\", \"ga(\"]):\n",
    "    print(\"‚úÖ Google Analytics detectado\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontr√≥ Google Analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf891ff",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 7: T√≠tulos y descripciones duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deddd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo m√∫ltiples URLs (solo simulaci√≥n con una por simplicidad)\n",
    "urls = [url]\n",
    "titulos = []\n",
    "descripciones = []\n",
    "\n",
    "for u in urls:\n",
    "    r = requests.get(u)\n",
    "    s = BeautifulSoup(r.text, 'html.parser')\n",
    "    titulo = s.title.string.strip() if s.title else \"\"\n",
    "    descripcion = s.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    desc = descripcion[\"content\"].strip() if descripcion and descripcion.get(\"content\") else \"\"\n",
    "    titulos.append(titulo)\n",
    "    descripciones.append(desc)\n",
    "\n",
    "print(\"Duplicados de t√≠tulo:\", [t for t in set(titulos) if titulos.count(t) > 1])\n",
    "print(\"Duplicados de descripci√≥n:\", [d for d in set(descripciones) if descripciones.count(d) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e476c4",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 8: Densidad de palabras clave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e420873",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b138e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "stopwords = {'de', 'la', 'y', 'el', 'en', 'los', 'las', 'con', 'por', 'una', 'para', 'que', 'del', 'sus', 'm√°s'}\n",
    "texto = soup.get_text().lower()\n",
    "palabras = re.findall(r'\\b\\w{4,}\\b', texto)\n",
    "palabras_filtradas = [p for p in palabras if p not in stopwords]\n",
    "total = len(palabras_filtradas)\n",
    "conteo = Counter(palabras_filtradas)\n",
    "for palabra, freq in conteo.most_common(10):\n",
    "    densidad = (freq / total) * 100\n",
    "    print(f\"{palabra}: {freq} veces - {densidad:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646edab",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 9: Validaci√≥n de sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitemap_url = url + \"/sitemap.xml\"\n",
    "try:\n",
    "    r = requests.get(sitemap_url)\n",
    "    if r.status_code == 200 and \"<loc>\" in r.text:\n",
    "        print(\"‚úÖ Sitemap encontrado\")\n",
    "    else:\n",
    "        print(\"‚ùå Sitemap no v√°lido o vac√≠o\")\n",
    "except:\n",
    "    print(\"‚ùå Error al acceder al sitemap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7320c12",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 10: Informe de auditor√≠a SEO b√°sica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86067e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "info = {\n",
    "    \"URL\": url,\n",
    "    \"Tiene <title>\": soup.title is not None,\n",
    "    \"Tiene <meta description>\": soup.find(\"meta\", attrs={\"name\": \"description\"}) is not None,\n",
    "    \"Un solo <h1>\": len(soup.find_all(\"h1\")) == 1,\n",
    "    \"Im√°genes sin alt\": sum(1 for img in soup.find_all(\"img\") if not img.get(\"alt\")),\n",
    "    \"Tiene canonical\": soup.find(\"link\", rel=\"canonical\") is not None,\n",
    "    \"Google Analytics\": any(x in response.text for x in [\"UA-\", \"G-\", \"gtag(\", \"ga(\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([info])\n",
    "df.to_excel(\"informe_seo_basico.xlsx\", index=False)\n",
    "print(\"‚úÖ Informe exportado a informe_seo_basico.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
